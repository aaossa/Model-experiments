{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colaboratory setup\n",
    "\n",
    "Clone repository contents in VM and install dependencies using the script:\n",
    "\n",
    "```python\n",
    "# (1) Replace contents of VM\n",
    "!rm -rf sample_data\n",
    "# (Replace username and password/token)\n",
    "!git clone --single-branch --branch master https://username:password@github.com/aaossa/CuratorNet-experiments.git\n",
    "!cp -a CuratorNet-experiments/. .\n",
    "!rm -r CuratorNet-experiments/\n",
    "# Setup VM using script\n",
    "!chmod +x ./scripts/colaboratory.sh\n",
    "!./scripts/colaboratory.sh requirements/dev.txt\n",
    "```\n",
    "\n",
    "Mount Google Drive in case the data is available there:\n",
    "\n",
    "```python\n",
    "# (2) Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "```\n",
    "\n",
    "Extract data in the right folder:\n",
    "\n",
    "```python\n",
    "# (3) Bring actual data to VM\n",
    "# Extract data from mounted drive to data folder\n",
    "!tar -xvzf \"/content/drive/My Drive/path_to_data/data.tar.gz\" -C data/UGallery\n",
    "```\n",
    "\n",
    "**Important:** Restart the VM after following the steps to make sure you're using the right version of the declared requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:53.542195Z",
     "start_time": "2020-04-06T15:20:53.367196Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "from datasets import ProfileModeDataset\n",
    "from models import CuratorNet\n",
    "from samplers import SameProfileSizeBatchSampler\n",
    "from trainers import Trainer\n",
    "from utils.data import extract_embedding\n",
    "from utils.memory import max_memory_stats, memory_report\n",
    "\n",
    "\n",
    "# Parameters\n",
    "RNG_SEED = 0\n",
    "DATASET = \"UGallery\"\n",
    "assert DATASET in [\"UGallery\", \"Wikimedia\", \"Pinterest\", \"Tradesy\"]\n",
    "FEATURE_EXTRACTOR = \"resnet50\"\n",
    "EMBEDDING_PATH = os.path.join(\"data\", DATASET, f\"{DATASET.lower()}_embedding-{FEATURE_EXTRACTOR}.npy\")\n",
    "TRAINING_PATH = os.path.join(\"data\", DATASET, \"profile-train.csv\")\n",
    "VALIDATION_PATH = os.path.join(\"data\", DATASET, \"profile-validation.csv\")\n",
    "SUMMARY_WRITER_DIR = os.path.join(\"runs\", \"CuratorNet\")\n",
    "CHECKPOINTS_DIR = os.path.join(\"checkpoints\", \"CuratorNet\")\n",
    "USE_GPU = True\n",
    "\n",
    "# Parameters (training)\n",
    "SETTINGS = {\n",
    "    \"batch_sampler:batch_size\": 4096 * 3,\n",
    "    \"batch_sampler:profile_items_per_batch\": 60_000,\n",
    "    \"dataloader:num_workers\": os.cpu_count(),\n",
    "    \"dataloader:pin_memory\": True,\n",
    "    \"optimizer:lr\": 0.0001,\n",
    "    \"optimizer:weight_decay\": 0.0001,\n",
    "    \"scheduler:factor\": 0.6,\n",
    "    \"scheduler:patience\": 2,\n",
    "    \"scheduler:threshold\": 1e-4,  # Default value (https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau)\n",
    "    \"train:max_epochs\": 150,\n",
    "    \"train:max_lrs\": 10,\n",
    "    \"train:non_blocking\": True,\n",
    "    \"train:train_per_valid_times\": 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Freezing RNG seed if needed\n",
    "if RNG_SEED is not None:\n",
    "    print(f\"\\nUsing random seed...\")\n",
    "    random.seed(RNG_SEED)\n",
    "    torch.manual_seed(RNG_SEED)\n",
    "    np.random.seed(RNG_SEED)\n",
    "\n",
    "# Load embedding from file\n",
    "print(f\"\\nLoading embedding from file... ({EMBEDDING_PATH})\")\n",
    "embedding = np.load(EMBEDDING_PATH, allow_pickle=True)\n",
    "\n",
    "\"\"\"\n",
    "# Additional embeddings\n",
    "# Color embedding\n",
    "COLOR_EMBEDDING_PATH = os.path.join(\"..\", \"..\", \"temp2\", \"colors_conv1.npy\")\n",
    "color_embedding = np.load(COLOR_EMBEDDING_PATH, allow_pickle=True)\n",
    "color_embedding = color_embedding.astype(float)\n",
    "# Texture embedding\n",
    "TEXTURE_EMBEDDING_PATH = os.path.join(\"..\", \"..\", \"temp2\", \"texture_relu.npy\")\n",
    "texture_embedding = np.load(TEXTURE_EMBEDDING_PATH, allow_pickle=True)\n",
    "texture_embedding = texture_embedding.astype(float)\n",
    "# Concatenation\n",
    "explicit_features = np.concatenate((color_embedding, texture_embedding), axis=-1)\n",
    "\"\"\"\n",
    "\n",
    "# Extract features and \"id2index\" mapping\n",
    "print(\"\\nExtracting data into variables...\")\n",
    "embedding, _, _ = extract_embedding(embedding, verbose=True)\n",
    "print(f\">> Features shape: {embedding.shape}\")\n",
    "\n",
    "# DataLoaders initialization\n",
    "print(\"\\nInitialize DataLoaders\")\n",
    "# Training DataLoader\n",
    "train_dataset = ProfileModeDataset(\n",
    "    csv_file=TRAINING_PATH,\n",
    ")\n",
    "print(f\">> Training dataset: {len(train_dataset)}\")\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_batch_sampler = SameProfileSizeBatchSampler(\n",
    "    sampler=train_sampler,\n",
    "    batch_size=SETTINGS[\"batch_sampler:batch_size\"],\n",
    "    profile_items_per_batch=SETTINGS[\"batch_sampler:profile_items_per_batch\"],\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_batch_sampler,\n",
    "    num_workers=SETTINGS[\"dataloader:num_workers\"],\n",
    "    pin_memory=SETTINGS[\"dataloader:pin_memory\"],\n",
    ")\n",
    "print(f\">> Training dataloader: {len(train_dataloader)}\")\n",
    "# Validation DataLoader\n",
    "valid_dataset = ProfileModeDataset(\n",
    "    csv_file=VALIDATION_PATH,\n",
    ")\n",
    "print(f\">> Validation dataset: {len(valid_dataset)}\")\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "valid_batch_sampler = SameProfileSizeBatchSampler(\n",
    "    sampler=valid_sampler,\n",
    "    batch_size=SETTINGS[\"batch_sampler:batch_size\"],\n",
    "    profile_items_per_batch=SETTINGS[\"batch_sampler:profile_items_per_batch\"],\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler=valid_batch_sampler,\n",
    "    num_workers=SETTINGS[\"dataloader:num_workers\"],\n",
    "    pin_memory=SETTINGS[\"dataloader:pin_memory\"],\n",
    ")\n",
    "print(f\">> Validation dataloader: {len(valid_dataloader)}\")\n",
    "# Model initialization\n",
    "print(\"\\nInitialize model\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
    "if torch.cuda.is_available() != USE_GPU:\n",
    "    print((f\"\\nNotice: Not using GPU - \"\n",
    "           f\"Cuda available ({torch.cuda.is_available()}) \"\n",
    "           f\"does not match USE_GPU ({USE_GPU})\"\n",
    "    ))\n",
    "model = CuratorNet(\n",
    "    torch.Tensor(embedding),\n",
    "    input_size=embedding.shape[1],\n",
    ").to(device)\n",
    "\n",
    "# Training setup\n",
    "print(\"\\nSetting up training\")\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=SETTINGS[\"optimizer:lr\"],\n",
    "    weight_decay=SETTINGS[\"optimizer:weight_decay\"],\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=SETTINGS[\"scheduler:factor\"],\n",
    "    patience=SETTINGS[\"scheduler:patience\"], verbose=True,\n",
    "    threshold=SETTINGS[\"scheduler:threshold\"],\n",
    ")\n",
    "\n",
    "# Crurent memory status\n",
    "print(\"\\nMemory report\")\n",
    "memory_report()\n",
    "print(\"\\nMax memory stats\")\n",
    "max_memory_stats(device)\n",
    "\n",
    "# Training\n",
    "print(\"\\nTraining\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training\n",
    "version = (\n",
    "    f\"{model.__class__.__name__}_\"\n",
    "    f\"{DATASET}_\"\n",
    "    f\"{time.strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model, device, criterion, optimizer, scheduler,\n",
    "    checkpoint_dir=CHECKPOINTS_DIR,\n",
    "    writer_dir=SUMMARY_WRITER_DIR,\n",
    "    version=version,\n",
    ")\n",
    "best_model, best_acc, best_loss, best_epoch = trainer.run(\n",
    "    SETTINGS[\"train:max_epochs\"], SETTINGS[\"train:max_lrs\"],\n",
    "    {\"train\": train_dataloader, \"validation\": valid_dataloader},\n",
    "    train_valid_loops=SETTINGS[\"train:train_per_valid_times\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crurent memory status\n",
    "print(\"\\nMemory report\")\n",
    "memory_report()\n",
    "print(\"\\nMax memory stats\")\n",
    "max_memory_stats(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result\n",
    "print(f\"\\nBest ACC {best_acc} reached at epoch {best_epoch}\")\n",
    "print(best_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.5",
   "language": "python",
   "name": "3.8.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
