{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models import CuratorNet, VBPR\n",
    "from utils.data import extract_embedding\n",
    "from utils.metrics import (\n",
    "    auc_exact,\n",
    "    nDCG,\n",
    "    precision,\n",
    "    recall,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colaboratory setup\n",
    "\n",
    "Clone repository contents in VM and install dependencies using the script:\n",
    "\n",
    "```python\n",
    "# (1) Replace contents of VM\n",
    "!rm -rf sample_data\n",
    "# (Replace username and password/token)\n",
    "!git clone --single-branch --branch master https://username:password@github.com/aaossa/CuratorNet-experiments.git\n",
    "!cp -a CuratorNet-experiments/. .\n",
    "!rm -r CuratorNet-experiments/\n",
    "# Setup VM using script\n",
    "!chmod +x ./scripts/colaboratory.sh\n",
    "!./scripts/colaboratory.sh requirements/dev.txt\n",
    "```\n",
    "\n",
    "Mount Google Drive in case the data is available there:\n",
    "\n",
    "```python\n",
    "# (2) Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "```\n",
    "\n",
    "Extract data in the right folder:\n",
    "\n",
    "```python\n",
    "# (3) Bring actual data to VM\n",
    "# Extract data from mounted drive to data folder\n",
    "!tar -xvzf \"/content/drive/My Drive/dataset/dataset.tar.gz\" -C data/dataset\n",
    "```\n",
    "\n",
    "**Important:** Restart the VM after following the steps to make sure you're using the right version of the declared requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# * UGallery\n",
    "# * Wikimedia\n",
    "# * Pinterest\n",
    "DATASET = \"UGallery\"\n",
    "assert DATASET in [\"UGallery\", \"Wikimedia\", \"Pinterest\"]\n",
    "\n",
    "# Model\n",
    "# * CuratorNet\n",
    "# * VBPR\n",
    "MODEL = \"CuratorNet\"\n",
    "assert MODEL in [\"CuratorNet\", \"VBPR\"]\n",
    "\n",
    "# Feature extractor\n",
    "FEATURE_EXTRACTOR = \"resnet50\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "# Use 'MODE_PROFILE = True' for CuratorNet-like training \n",
    "# Use 'MODE_PROFILE = False' for VBPR-like training\n",
    "MODE_PROFILE = MODEL in [\"CuratorNet\"]\n",
    "MODE_PROFILE = \"profile\" if MODE_PROFILE else \"user\"\n",
    "\n",
    "# Checkpoint (ex. 'CuratorNet_2020-08-07-23-59-50')\n",
    "CHECKPOINT = \"CuratorNet_2020-08-09-01-35-38\"\n",
    "if CHECKPOINT is not None:\n",
    "    assert CHECKPOINT.startswith(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (general)\n",
    "CHECKPOINT_PATH = os.path.join(\"checkpoints\", MODEL, f\"{CHECKPOINT}.tar\")\n",
    "EMBEDDING_PATH = os.path.join(\"data\", DATASET, f\"{DATASET.lower()}_embedding-{FEATURE_EXTRACTOR}.npy\")\n",
    "EVALUATION_PATH = os.path.join(\"data\", DATASET, f\"{MODE_PROFILE}-evaluation.csv\")\n",
    "\n",
    "# General constants\n",
    "RNG_SEED = 0\n",
    "USE_GPU = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing RNG seed if needed\n",
    "if RNG_SEED is not None:\n",
    "    print(f\"\\nUsing random seed... ({RNG_SEED})\")\n",
    "    torch.manual_seed(RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding from file\n",
    "print(f\"\\nLoading embedding from file... ({EMBEDDING_PATH})\")\n",
    "embedding = np.load(EMBEDDING_PATH, allow_pickle=True)\n",
    "\n",
    "# Extract features and \"id2index\" mapping\n",
    "print(\"\\nExtracting data into variables...\")\n",
    "features, _ = extract_embedding(embedding, verbose=True)\n",
    "print(f\">> Features shape: {features.shape}\")\n",
    "del embedding  # Release some memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation dataframe\n",
    "print(\"\\nLoad evaluation dataframe\")\n",
    "evaluation_df = pd.read_csv(EVALUATION_PATH)\n",
    "# Transform lists from str to int\n",
    "string_to_list = lambda s: list(map(int, s.split()))\n",
    "evaluation_df[\"profile\"] = evaluation_df[\"profile\"].apply(\n",
    "    lambda s: string_to_list(s) if isinstance(s, str) else s,\n",
    ")\n",
    "evaluation_df[\"predict\"] = evaluation_df[\"predict\"].apply(\n",
    "    lambda s: string_to_list(s) if isinstance(s, str) else s,\n",
    ")\n",
    "print(f\">> Evaluation: {evaluation_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create device instance\n",
    "print(\"\\nDevice initialization\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
    "if torch.cuda.is_available() != USE_GPU:\n",
    "    print((f\"\\nNotice: Not using GPU - \"\n",
    "           f\"Cuda available ({torch.cuda.is_available()}) \"\n",
    "           f\"does not match USE_GPU ({USE_GPU})\"\n",
    "    ))\n",
    "\n",
    "# Loading checkpoint\n",
    "if CHECKPOINT is not None:\n",
    "    print(\"\\nLoading checkpoint\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device(\"cpu\"))\n",
    "    print(f\">> Best epoch: {checkpoint['epoch']} | Best accuracy: {checkpoint['accuracy']}\")\n",
    "\n",
    "# Model initialization\n",
    "print(\"\\nModel initialization\")\n",
    "model = None\n",
    "if MODEL == \"CuratorNet\":\n",
    "    model = CuratorNet(\n",
    "        torch.Tensor(features),  # Pretrained visual features\n",
    "        input_size=features.shape[1],  # Network input size\n",
    "    ).to(device)\n",
    "elif MODEL == \"VBPR\":\n",
    "    n_users = checkpoint[\"model\"][\"gamma_users.weight\"].size(0)\n",
    "    n_items = checkpoint[\"model\"][\"gamma_items.weight\"].size(0)\n",
    "    dim_gamma = checkpoint[\"model\"][\"gamma_users.weight\"].size(1)\n",
    "    dim_theta = checkpoint[\"model\"][\"theta_users.weight\"].size(1)\n",
    "    model = VBPR(\n",
    "        n_users, n_items,  # Number of users and items\n",
    "        torch.Tensor(features),  # Pretrained visual features\n",
    "        dim_gamma, dim_theta,  # Size of internal spaces\n",
    "    ).to(device)\n",
    "\n",
    "# Load state dict\n",
    "if CHECKPOINT is not None:\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    \n",
    "# Change model mode to eval\n",
    "print(\"\\nChanging model mode to eval\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Metrics\n",
    "N_EVALS = len(evaluation_df.index)\n",
    "# Area Under the Curve (AUC)\n",
    "AUC = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "# Recall\n",
    "R20 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "R100 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "# Precision\n",
    "P20 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "P100 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "# Normalized discounted cumulative gain (nDCG)\n",
    "N20 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "N100 = torch.zeros([N_EVALS], dtype=torch.float64, device=device)\n",
    "PROFILE_SIZES = torch.zeros([N_EVALS], dtype=int, device=device)\n",
    "N_ITEMS = len(features)\n",
    "\n",
    "\n",
    "try:\n",
    "    items_cache = model.generate_items_cache()\n",
    "except NotImplementedError:\n",
    "    items_cache = None\n",
    "\n",
    "\n",
    "for i, row in tqdm(enumerate(evaluation_df.itertuples()), total=len(evaluation_df.index)):\n",
    "    # Load data into tensors\n",
    "    profile = torch.tensor(row.profile).to(device, non_blocking=True).unsqueeze(0)\n",
    "    user_id = torch.tensor([int(row.user_id)]).to(device, non_blocking=True)\n",
    "    predict = torch.tensor(row.predict).to(device, non_blocking=True)\n",
    "    # Prediction\n",
    "    if MODE_PROFILE == \"profile\":\n",
    "        scores = model.recommend(profile, items_cache=items_cache)\n",
    "    elif MODE_PROFILE == \"user\":\n",
    "        scores = model.recommend(user_id, items_cache=items_cache).squeeze()\n",
    "    # Ranking\n",
    "    pos_of_evals = (torch.argsort(scores, descending=True)[..., None] == predict).any(-1).nonzero().flatten()\n",
    "    # Store metrics\n",
    "    AUC[i] = auc_exact(pos_of_evals, N_ITEMS)\n",
    "    R20[i] = recall(pos_of_evals, 20)\n",
    "    P20[i] = precision(pos_of_evals, 20)\n",
    "    N20[i] = nDCG(pos_of_evals, 20)\n",
    "    R100[i] = recall(pos_of_evals, 100)\n",
    "    P100[i] = precision(pos_of_evals, 100)\n",
    "    N100[i] = nDCG(pos_of_evals, 100)\n",
    "    PROFILE_SIZES[i] = len(row.profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stats\n",
    "print(f\"AVG AUC = {AUC.mean()}\")\n",
    "print(f\"AVG R20 = {R20.mean()}\")\n",
    "print(f\"AVG P20 = {P20.mean()}\")\n",
    "print(f\"AVG NDCG20 = {N20.mean()}\")\n",
    "print(f\"AVG R100 = {R100.mean()}\")\n",
    "print(f\"AVG P100 = {P100.mean()}\")\n",
    "print(f\"AVG NDCG100 = {N100.mean()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.5",
   "language": "python",
   "name": "3.8.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
