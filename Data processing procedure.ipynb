{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:53.542195Z",
     "start_time": "2020-04-06T15:20:53.367196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:54.037576Z",
     "start_time": "2020-04-06T15:20:53.545796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.0.2 from /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages/pip (python 3.8)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:54.050074Z",
     "start_time": "2020-04-06T15:20:54.043061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1 (default, Mar  3 2020, 17:56:59) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:55.936861Z",
     "start_time": "2020-04-06T15:20:54.053799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.1 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from -r requirements/common.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn==0.22.2.post1 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from -r requirements/common.txt (line 2)) (0.22.2.post1)\n",
      "Requirement already satisfied: line_profiler==3.0.2 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from -r requirements/dev.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: tqdm==4.45.0 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from -r requirements/dev.txt (line 3)) (4.45.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1->-r requirements/common.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1->-r requirements/common.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: IPython in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (7.13.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: decorator in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (4.4.2)\n",
      "Requirement already satisfied: pygments in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: backcall in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (45.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied: wcwidth in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.1.8)\n",
      "Requirement already satisfied: six in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from traitlets>=4.2->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from traitlets>=4.2->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from jedi>=0.10->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -r requirements/dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:56.169307Z",
     "start_time": "2020-04-06T15:20:55.944668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artwork_id2artist.json\t evaluation.json  ugallery_inventory.csv\r\n",
      "artwork_id2cluster.json  README.md\t  ugallery_purchases.csv\r\n",
      "artwork_id2index.json\t Readme.txt\t  ugallery_resnet50_embeddings.npy\r\n",
      "clustering.json\t\t train.csv\t  validation.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/UGallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:56.430280Z",
     "start_time": "2020-04-06T15:20:56.178226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artwork_id_hash,artist_id_hash,upload_timestamp\r\n",
      "9338d925a4f391d049f1cb55be83206d,ac648ab20e0c330dcfaa912644abcc2f,0\r\n",
      "6ff620bdd4b7143ef7ef9a43ae35379f,dfc6c382d6584b22b5ba75c62cdb0c56,0\r\n",
      "ec4708be07b9b92dfd3c98b92d5b273e,e836b4d62ec611a38ce9dd6e394a65e1,1\r\n",
      "bb8fe17afcd2b8a8700155b79980a7d9,942050a4fd56327fb69ecb8b81948ded,2\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/UGallery/ugallery_inventory.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:56.653645Z",
     "start_time": "2020-04-06T15:20:56.433825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_hash,purchase_timestamp,purchased_artwork_ids_hash\r\n",
      "faaecc910173fcca8b146c66db26b99f,1416,['f196009db1ba9607150abf0570e0fffe']\r\n",
      "90d6d470c21861aaa739b2811ac0df3c,1418,['ccccb1b02d3130e435e05a4eea7d11fd']\r\n",
      "67c7793eefa4aca1cd9a18029b26efc6,1420,['7bbc45a178aef2c041f4376ecdc26b23']\r\n",
      "8c872e88b91f7077527d8c7bf8892fbd,1424,['5775ae42d3cef7ea7f56b800a8d7cffc']\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/UGallery/ugallery_purchases.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:56.827997Z",
     "start_time": "2020-04-06T15:20:56.659713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to privacy and copyright restrictions, we are only able to release part of the user transactions data, which consists of 6535 transactions of 2919 users on 6030 items.\r\n",
      "\r\n",
      "Files under this folder:\r\n",
      "\r\n",
      "* ugallery_purchases.csv  \r\n",
      "Each line is a tuple in the form of (user_id_hash, purchase_timestamp, artwork_id_hash). Note that each id_hash is an 32-char string.\r\n",
      "This file has the purchases in time for each user, the test data is the last purchase of each user.\r\n",
      "\r\n",
      "* ugallery_inventory.csv  \r\n",
      "Each line is a tuple in the form of (artwork_id_hash, artist_id_hash, upload_timestamp). Note that each id_hash is an 32-char string.\r\n",
      "This file has the time an item is added to the website inventory, because these are physical artworks, the availability of the items must be simulated in order to make the recommendations.\r\n",
      "\r\n",
      "* ugallery_resnet50_embeddings.npy\r\n",
      "This is a numpy array of shape (13297, 2), each row is of shape (2,) where the first value is the artwork_id_hash, and the second one is the Resnet50 embedding of the artwork image.\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/UGallery/Readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:57.126593Z",
     "start_time": "2020-04-06T15:20:56.832845Z"
    }
   },
   "outputs": [],
   "source": [
    "# ugallery_data_utils.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_embeddings(embedding_path, embedding_shape=(13297, 2048)):\n",
    "    data = np.load(embedding_path, allow_pickle=True)\n",
    "    # Generate indexes and contiguous embedding\n",
    "    embedding = np.zeros(shape=embedding_shape)\n",
    "    artwork_id2index = dict()\n",
    "    artwork_index2id = dict()\n",
    "    for i, (artwork_id_hash, artwork_embedding) in enumerate(data):\n",
    "        assert artwork_id_hash not in artwork_id2index\n",
    "        artwork_id2index[artwork_id_hash] = i\n",
    "        assert i not in artwork_index2id \n",
    "        artwork_index2id[i] = artwork_id_hash\n",
    "        assert not np.any(embedding[i])\n",
    "        embedding[i] = artwork_embedding\n",
    "    assert not np.all(embedding == 0)\n",
    "    assert artwork_id2index\n",
    "    assert artwork_index2id\n",
    "    return embedding, artwork_id2index, artwork_index2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing procesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:58.366549Z",
     "start_time": "2020-04-06T15:20:57.128782Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "from os.path import join\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:20:58.400371Z",
     "start_time": "2020-04-06T15:20:58.369004Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating visual clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:02.137093Z",
     "start_time": "2020-04-06T15:20:58.404342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape: (13297, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings from files\n",
    "embeddings_path = join(\"data\", \"UGallery\", \"ugallery_resnet50_embeddings.npy\")\n",
    "loaded_data = load_embeddings(embeddings_path)\n",
    "embeddings, artwork_id2index, artwork_index2id = loaded_data\n",
    "print(f\"embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:04.888638Z",
     "start_time": "2020-04-06T15:21:02.140967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score normalization result shape: (13297, 2048)\n"
     ]
    }
   ],
   "source": [
    "# z-score normalization of embedding\n",
    "embeddings = StandardScaler().fit_transform(embeddings)\n",
    "print(f\"z-score normalization result shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:12.136129Z",
     "start_time": "2020-04-06T15:21:04.893191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduction result shape: (13297, 200)\n"
     ]
    }
   ],
   "source": [
    "# 1. Conduct PCA to reduce from R2048 to R200\n",
    "embeddings = PCA(n_components=200).fit_transform(embeddings)\n",
    "print(f\"PCA reduction result shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:48.786225Z",
     "start_time": "2020-04-06T15:21:12.139942Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score (1): 0.005575877828699279 - New highest!\n",
      "Silhouette score (2): 0.008471017175563205 - New highest!\n",
      "Silhouette score (3): 0.005023989246338093\n",
      "Silhouette score (4): 0.002515468167700846\n",
      "Silhouette score (5): 0.0043125655553497184\n",
      "Silhouette score (6): 0.004074349921113054\n",
      "Silhouette score (7): 0.005346213261036431\n",
      "Silhouette score (8): 0.008720916554128124 - New highest!\n",
      "Silhouette score (9): 0.004183795853951518\n",
      "Silhouette score (10): 0.005244780972843033\n",
      "Silhouette score (11): 0.008017755480061253\n",
      "Silhouette score (12): 0.002300760674216923\n",
      "Silhouette score (13): 0.0069804428818633505\n",
      "Silhouette score (14): 0.005136548763804483\n",
      "Silhouette score (15): 0.002009563673710783\n",
      "Silhouette score (16): 0.004639126643139413\n",
      "Silhouette score (17): 0.005459811198245649\n",
      "Silhouette score (18): 0.005601142001905458\n",
      "Silhouette score (19): 0.003948618280922595\n",
      "Silhouette score (20): 0.00708712264970234\n",
      ">> Best Silhouette score: 0.008720916554128124\n"
     ]
    }
   ],
   "source": [
    "# 2. Perform k-means clustering with 100 clusters 20 times\n",
    "# and keep the clusterer with the highest Silhouette coefficient\n",
    "best_score = float(\"-inf\")\n",
    "best_clusterer = None\n",
    "\n",
    "for i in range(20):\n",
    "    clusterer = KMeans(\n",
    "        n_clusters=100,\n",
    "        max_iter=2000,\n",
    "        n_init=8,\n",
    "        n_jobs=8\n",
    "    ).fit(embeddings)\n",
    "    clusterer_labels = clusterer.predict(embeddings)\n",
    "    clusterer_score = silhouette_score(embeddings, clusterer_labels)\n",
    "    if clusterer_score > best_score:\n",
    "        best_score = clusterer_score\n",
    "        best_clusterer = clusterer\n",
    "        print(f\"Silhouette score ({i + 1}): {clusterer_score} - New highest!\")\n",
    "    else:\n",
    "        print(f\"Silhouette score ({i + 1}): {clusterer_score}\")\n",
    "\n",
    "print(f\">> Best Silhouette score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:48.884271Z",
     "start_time": "2020-04-06T15:21:48.792027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clusterer Silhouette score: 0.008720916554128124\n",
      "There are n_clusters: 100\n"
     ]
    }
   ],
   "source": [
    "# 3. Label each image with its respective visual cluster\n",
    "clusterer_labels = best_clusterer.predict(embeddings)\n",
    "print(f\"Best clusterer Silhouette score: {best_score}\")\n",
    "\n",
    "artwork_id2cluster = dict()\n",
    "artwork_cluster2id = defaultdict(list)\n",
    "for i, label in enumerate(clusterer_labels):\n",
    "    artwork_id = artwork_index2id[i]\n",
    "    artwork_id2cluster[artwork_id] = label\n",
    "    artwork_cluster2id[label].append(artwork_id)\n",
    "\n",
    "n_clusters = len(set(artwork_id2cluster.values()))\n",
    "print(f\"There are n_clusters: {n_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:48.947923Z",
     "start_time": "2020-04-06T15:21:48.889718Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ugallery_data_utils.py\n",
    "class User:\n",
    "    def __init__(self, user_id_hash):\n",
    "        self.user_id_hash = user_id_hash\n",
    "        self.baskets = dict()\n",
    "        self.gt_baskets = dict()\n",
    "        self.evaluation_basket = None\n",
    "        self.liked_artists = None\n",
    "        self.liked_clusters = None\n",
    "        self.profile = None\n",
    "\n",
    "    def add_purchase(self, purchased_items, timestamp):\n",
    "        assert timestamp not in self.baskets\n",
    "        timestamp = int(timestamp)\n",
    "        # Baskets are assumed to contain each item once\n",
    "        self.baskets[timestamp] = set(purchased_items)\n",
    "        self.gt_baskets[timestamp] = set(purchased_items)\n",
    "\n",
    "    def assert_baskets(self):\n",
    "        assert isinstance(self.baskets, dict)\n",
    "        assert isinstance(self.evaluation_basket, set)\n",
    "        assert isinstance(self.gt_baskets, dict)\n",
    "        if len(self.evaluation_basket):\n",
    "            misses = 0\n",
    "            for gt_timestamp, gt_basket in self.gt_baskets.items():\n",
    "                if gt_timestamp in self.baskets:\n",
    "                    assert gt_basket == self.baskets[gt_timestamp]\n",
    "                else:\n",
    "                    misses += 1\n",
    "                    assert gt_basket == self.evaluation_basket\n",
    "            assert misses == 1\n",
    "        else:\n",
    "            assert self.baskets == self.gt_baskets\n",
    "\n",
    "    def create_profile(self):\n",
    "        assert self.profile is None\n",
    "        self.profile = list(\n",
    "            set(item for basket in self.baskets.values() for item in basket))\n",
    "\n",
    "    def create_likes(self, artwork_id2cluster, artwork_id2artist):\n",
    "        self.liked_clusters = set(artwork_id2cluster[item]\n",
    "                                  for item in self.profile)\n",
    "        self.liked_artists = set(artwork_id2artist[item]\n",
    "                                 for item in self.profile)\n",
    "\n",
    "    def save_basket_for_evaluation(self):\n",
    "        assert self.evaluation_basket is None\n",
    "        # If user has a single basket, use it for training only\n",
    "        if len(self.baskets) == 1:\n",
    "            self.evaluation_basket = set()\n",
    "            return\n",
    "        # All baskets are still available in self.gt_baskets\n",
    "        last_basket_timestamp = max(self.baskets.keys())\n",
    "        assert last_basket_timestamp in self.baskets\n",
    "        last_basket = self.baskets.pop(last_basket_timestamp)\n",
    "        assert last_basket is not None\n",
    "        self.evaluation_basket = last_basket\n",
    "\n",
    "    def strategy_1_valid_baskets(self, min_size=0):\n",
    "        return [(timestamp, basket)\n",
    "                for timestamp, basket in self.baskets.items()\n",
    "                if len(basket) >= min_size]\n",
    "\n",
    "    def strategy_2_valid_partitions(self):\n",
    "        sorted_timestamps = sorted(self.baskets)\n",
    "        valid_partitions = []\n",
    "        for i in range(1, len(sorted_timestamps)):\n",
    "            profile = {\n",
    "                item\n",
    "                for timestamp in sorted_timestamps[:i]\n",
    "                for item in self.baskets[timestamp]\n",
    "            }\n",
    "            timestamp = sorted_timestamps[i]\n",
    "            basket = self.baskets[timestamp]\n",
    "            valid_partitions.append((timestamp, profile, basket))\n",
    "        return valid_partitions\n",
    "\n",
    "    def strategy_3_valid_liked(self, artwork_cluster2id, artwork_artist2id):\n",
    "        liked_clusters_artworks = {\n",
    "            artwork\n",
    "            for cluster in self.liked_clusters\n",
    "            for artwork in artwork_cluster2id[cluster]\n",
    "        }\n",
    "        liked_artists_artworks = {\n",
    "            artwork\n",
    "            for artist in self.liked_artists\n",
    "            for artwork in artwork_artist2id[artist]\n",
    "        }\n",
    "        positive_candidates = liked_clusters_artworks & liked_artists_artworks\n",
    "        valid_liked = positive_candidates - set(self.profile)\n",
    "        return valid_liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:49.910854Z",
     "start_time": "2020-04-06T15:21:48.953504Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaossa/Hito 1 - Pipeline y modelos baseline/environment/pytorch_aaossa/lib/python3.8/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ugallery_data_utils.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Inventory:\n",
    "    def __init__(self, inventory_path, purchases_path):\n",
    "        self.users = None\n",
    "        # Build dataframes to manage data\n",
    "        self.inventory = pd.read_csv(inventory_path)\n",
    "        self.purchases = pd.read_csv(purchases_path)\n",
    "        self.inventory.rename(\n",
    "            columns={\"upload_timestamp\": \"timestamp\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "        self.purchases.rename(\n",
    "            columns={\"purchase_timestamp\": \"timestamp\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        # Check if artwork_id_hash has duplicates (inventory)\n",
    "        assert not self.inventory[\"artwork_id_hash\"].duplicated().any()\n",
    "        # Check for missing values in data (inventory)\n",
    "        assert not self.inventory.isnull().values.any()\n",
    "        # Check for missing values in data (purchases)\n",
    "        assert not self.purchases.isnull().values.any()\n",
    "        # Process purchased artworks column (purchases)\n",
    "        purchases_to_list = lambda p: p[1:-1].replace(\"'\", \"\").split(\", \")\n",
    "        self.purchases[\"purchased_artwork_ids_hash\"] = self.purchases[\n",
    "            \"purchased_artwork_ids_hash\"].map(purchases_to_list)\n",
    "        # Check if all purchases contain elements\n",
    "        assert all(p for p in self.purchases[\"purchased_artwork_ids_hash\"])\n",
    "\n",
    "        # Find non-unique items\n",
    "        purchased_items = self.purchases[\"purchased_artwork_ids_hash\"].sum()\n",
    "        self.non_unique_items, seen = set(), set()\n",
    "        for item in purchased_items:\n",
    "            if item not in seen:\n",
    "                seen.add(item)\n",
    "            else:\n",
    "                self.non_unique_items.add(item)\n",
    "        # Create list with items ids\n",
    "        self.items = tuple(self.inventory[\"artwork_id_hash\"].unique())\n",
    "\n",
    "\n",
    "    def available_at_t(self, up_to_timestamp=None):\n",
    "        inventory = set()\n",
    "        # Forward time by timestamp\n",
    "        for step, timestamp, row in self.__forward_time(up_to_timestamp):\n",
    "            # Add item to inventory\n",
    "            if step == \"Add item\":\n",
    "                item = row[\"artwork_id_hash\"]\n",
    "                if item in inventory:\n",
    "                    # Item already present\n",
    "                    pass\n",
    "                inventory.add(item)\n",
    "            # Remove item if purchased item is not unique\n",
    "            elif step == \"Sell items\":\n",
    "                for item in row[\"purchased_artwork_ids_hash\"]:\n",
    "                    if item not in inventory:\n",
    "                        # Item already sold or not present\n",
    "                        if item not in self.non_unique_items:\n",
    "                            # Item already sold or nor present\n",
    "                            pass\n",
    "                    if item not in self.non_unique_items:\n",
    "                        inventory.discard(item)\n",
    "        return inventory\n",
    "    \n",
    "    def build_users(self, artwork_id2cluster, artwork_id2artist):\n",
    "        self.__build_users(artwork_id2cluster, artwork_id2artist)\n",
    "        assert isinstance(self.users, dict)\n",
    "        # Check if all users were built\n",
    "        users_in_df = set(self.purchases[\"user_id_hash\"].unique())\n",
    "        users_in_dict = set(self.users.keys())\n",
    "        assert users_in_df == users_in_dict\n",
    "        # Check if all users are present in dict\n",
    "        assert all(self.purchases[\"user_id_hash\"].isin(self.users.keys()))\n",
    "        # Check if user profiles were created\n",
    "        assert all(user.profile for user in self.users.values())\n",
    "        # Check if all users have evaluation basket or a single purchase\n",
    "        assert all(user.evaluation_basket is not None\n",
    "                   for user in self.users.values())\n",
    "        assert all(user.assert_baskets for user in self.users.values())\n",
    "\n",
    "    def __build_users(self, artwork_id2cluster, artwork_id2artist):\n",
    "        self.users = dict()\n",
    "        purchases = 0\n",
    "        inventory = 0\n",
    "        for step, timestamp, row in self.__forward_time():\n",
    "            if step != \"Sell items\":\n",
    "                inventory += 1\n",
    "                continue\n",
    "            purchases += 1\n",
    "            if row[\"user_id_hash\"] not in self.users:\n",
    "                user_id_hash = row[\"user_id_hash\"]\n",
    "                self.users[user_id_hash] = User(user_id_hash)\n",
    "            user = self.users[user_id_hash]\n",
    "            user.add_purchase(\n",
    "                row[\"purchased_artwork_ids_hash\"],\n",
    "                row[\"timestamp\"],\n",
    "            )\n",
    "        assert purchases == len(self.purchases)\n",
    "        assert inventory == len(self.inventory)\n",
    "        for _, user in self.users.items():\n",
    "            user.save_basket_for_evaluation()\n",
    "            user.create_profile()\n",
    "            user.create_likes(artwork_id2cluster, artwork_id2artist)\n",
    "\n",
    "    def __forward_time(self, up_to_timestamp=None):\n",
    "        # Sort data by timestamp\n",
    "        df_inventory = self.inventory.sort_values(by=[\"timestamp\"])\n",
    "        df_purchases = self.purchases.sort_values(by=[\"timestamp\"])\n",
    "        # Limits of iteration\n",
    "        i_inventory, max_inventory = 0, len(df_inventory.index)\n",
    "        i_purchases, max_purchases = 0, len(df_purchases.index)\n",
    "        # First row of dataframes\n",
    "        row_inventory = df_inventory.loc[i_inventory, :]\n",
    "        row_purchases = df_purchases.loc[i_purchases, :]\n",
    "\n",
    "        while row_inventory is not None or row_purchases is not None:\n",
    "            # If next timestamp is an upload\n",
    "            time_inventory = getattr(row_inventory, \"timestamp\", float(\"inf\"))\n",
    "            time_purchases = getattr(row_purchases, \"timestamp\", float(\"inf\"))\n",
    "            if time_inventory <= time_purchases:\n",
    "                yield (\"Add item\", time_inventory, row_inventory)\n",
    "                i_inventory += 1\n",
    "                if i_inventory >= max_inventory:\n",
    "                    row_inventory = None\n",
    "                else:\n",
    "                    row_inventory = df_inventory.loc[i_inventory, :]\n",
    "            # If next timestamp is a purchase\n",
    "            elif time_purchases < time_inventory:\n",
    "                yield (\"Sell items\", time_purchases, row_purchases)\n",
    "                i_purchases += 1\n",
    "                if i_purchases >= max_purchases:\n",
    "                    row_purchases = None\n",
    "                else:\n",
    "                    row_purchases = df_purchases.loc[i_purchases, :]\n",
    "            # If limit was given\n",
    "            if up_to_timestamp is not None:\n",
    "                if min(time_inventory, time_purchases) > up_to_timestamp:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:49.926086Z",
     "start_time": "2020-04-06T15:21:49.914623Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_SAMPLES_TRAIN = 10_000_000\n",
    "TOTAL_SAMPLES_VALID = TOTAL_SAMPLES_TRAIN * 0.05\n",
    "\n",
    "N_STRATEGIES = 6\n",
    "N_SAMPLES_PER_STRATEGY_TRAIN = ceil(TOTAL_SAMPLES_TRAIN / N_STRATEGIES)\n",
    "N_SAMPLES_PER_STRATEGY_VALID = ceil(TOTAL_SAMPLES_VALID / N_STRATEGIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:50.192357Z",
     "start_time": "2020-04-06T15:21:49.931211Z"
    }
   },
   "outputs": [],
   "source": [
    "inventory_path = join(\"data\", \"UGallery\", \"ugallery_inventory.csv\")\n",
    "purchases_path = join(\"data\", \"UGallery\", \"ugallery_purchases.csv\")\n",
    "inventory = Inventory(inventory_path, purchases_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:50.220467Z",
     "start_time": "2020-04-06T15:21:50.195902Z"
    }
   },
   "outputs": [],
   "source": [
    "artwork_id2artist = dict(\n",
    "    zip(\n",
    "        inventory.inventory[\"artwork_id_hash\"],\n",
    "        inventory.inventory[\"artist_id_hash\"],\n",
    "    ))\n",
    "artwork_artist2id = defaultdict(list)\n",
    "for artwork_id, artist_id in artwork_id2artist.items():\n",
    "    artwork_artist2id[artist_id].append(artwork_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:56.667460Z",
     "start_time": "2020-04-06T15:21:50.224653Z"
    }
   },
   "outputs": [],
   "source": [
    "inventory.build_users(artwork_id2cluster, artwork_id2artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:56.688527Z",
     "start_time": "2020-04-06T15:21:56.675640Z"
    }
   },
   "outputs": [],
   "source": [
    "class HashesContainer:\n",
    "\n",
    "    _MOD = 402653189\n",
    "    _BASE = 92821\n",
    "\n",
    "    def __init__(self):\n",
    "        self.collisions = 0\n",
    "        self.hashes = set()\n",
    "        self.samples = list()\n",
    "\n",
    "    def enroll(self, element, check_collision=False):\n",
    "        h = self.__hash_triple(element[0], element[1], element[2])\n",
    "        if h in self.hashes:\n",
    "            self.collisions += 1\n",
    "            return False\n",
    "        self.hashes.add(h)\n",
    "        self.samples.append(element)\n",
    "        return True\n",
    "\n",
    "    def __hash_triple(self, profile, pi, ni):\n",
    "        h = 0\n",
    "        for x in profile:\n",
    "            h = ((h * self._BASE) % self._MOD + int(x, 32)) % self._MOD\n",
    "        h = ((h * self._BASE) % self._MOD + int(pi, 32)) % self._MOD\n",
    "        h = ((h * self._BASE) % self._MOD + int(ni, 32)) % self._MOD\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:56.703584Z",
     "start_time": "2020-04-06T15:21:56.692949Z"
    }
   },
   "outputs": [],
   "source": [
    "hashes_container = HashesContainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Predicting missing item in purchase basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:21:56.725509Z",
     "start_time": "2020-04-06T15:21:56.706183Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 1. Predicting missing item in purchase basket\n",
    "\n",
    "\n",
    "def generate_samples_strategy_1(n_samples, users, items, hashes_container):\n",
    "    print(\"Strategy 1) Predicting missing item in purchase basket\")\n",
    "    # Count valid users\n",
    "    valid_users = 0\n",
    "    for user in users.values():\n",
    "        if user.strategy_1_valid_baskets(min_size=2):\n",
    "            valid_users += 1\n",
    "\n",
    "    samples_per_user = ceil(n_samples / valid_users)\n",
    "    print(\n",
    "        f\"Valid users: {valid_users} | Samples/user: {samples_per_user}\\n\"\n",
    "        f\"Target: {n_samples} | Total samples: {valid_users * samples_per_user}\"\n",
    "    )\n",
    "    initial_collisions = hashes_container.collisions\n",
    "\n",
    "    samples = []\n",
    "    for user in tqdm(users.values(), desc=\"Valid users\"):\n",
    "        # Pick items from baskets with more than one item\n",
    "        valid_baskets = user.strategy_1_valid_baskets(min_size=2)\n",
    "        if not valid_baskets: continue\n",
    "        # Pick visual clusters and artists liked by the user\n",
    "        liked_clusters = set(artwork_id2cluster[item] for item in user.profile)\n",
    "        liked_artists = set(artwork_id2artist[item] for item in user.profile)\n",
    "\n",
    "        n = samples_per_user\n",
    "        while n > 0:\n",
    "            ni = random.choice(items)\n",
    "            if artwork_id2cluster[ni] in liked_clusters: continue\n",
    "            if artwork_id2artist[ni] in liked_artists: continue\n",
    "            timestamp, basket = random.choice(valid_baskets)\n",
    "            pi = random.choice(tuple(basket))\n",
    "            profile = {item for item in basket if item != pi}\n",
    "            triple = (profile, pi, ni, timestamp, user.user_id_hash)\n",
    "            if not hashes_container.enroll(triple): continue\n",
    "            samples.append(triple)\n",
    "            n -= 1\n",
    "    final_collisions = hashes_container.collisions\n",
    "    print(f\"Hash collisions: {final_collisions - initial_collisions}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strategy_1(samples, users, artwork_id2cluster, artwork_id2artist):\n",
    "    print(\"Strategy 1) Predicting missing item in purchase basket\")\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni, timestamp, uid) in tqdm(samples, desc=\"Check S1\"):\n",
    "        user = users[uid]\n",
    "        gt_basket = user.baskets[timestamp]\n",
    "        assert len(profile) + 1 == len(gt_basket)\n",
    "        # Positive item\n",
    "        assert pi in gt_basket\n",
    "        # (Might not be true)\n",
    "        assert pi not in profile\n",
    "        # Negative item\n",
    "        assert ni not in user.profile\n",
    "        assert artwork_id2cluster[ni] not in user.liked_clusters\n",
    "        assert artwork_id2artist[ni] not in user.liked_artists\n",
    "        # Profile\n",
    "        assert profile.issubset(gt_basket)\n",
    "        assert profile.issubset(user.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:22:30.362582Z",
     "start_time": "2020-04-06T15:21:56.729084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 1) Predicting missing item in purchase basket\n",
      "Valid users: 625 | Samples/user: 2667\n",
      "Target: 1666667 | Total samples: 1666875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8824c47953f642178216de9413631aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 137119\n",
      "Strategy 1) Predicting missing item in purchase basket\n",
      "Samples: 1666875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0219c315cd1b4963a59266cde36ae685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S1', max=1666875.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 1) Predicting missing item in purchase basket\n",
      "Valid users: 625 | Samples/user: 134\n",
      "Target: 83334 | Total samples: 83750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a8488400bb43e0866500dbd4bdc4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 15252\n",
      "Strategy 1) Predicting missing item in purchase basket\n",
      "Samples: 83750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03e1454026a4323badeabc7c6fc2a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S1', max=83750.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train - Strategy 1\n",
    "samples_s1_train = generate_samples_strategy_1(\n",
    "    N_SAMPLES_PER_STRATEGY_TRAIN,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_1(\n",
    "    samples_s1_train,\n",
    "    inventory.users,\n",
    "    artwork_id2cluster,\n",
    "    artwork_id2artist,\n",
    ")\n",
    "# Validation - Strategy 1\n",
    "samples_s1_valid = generate_samples_strategy_1(\n",
    "    N_SAMPLES_PER_STRATEGY_VALID,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_1(\n",
    "    samples_s1_valid,\n",
    "    inventory.users,\n",
    "    artwork_id2cluster,\n",
    "    artwork_id2artist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Predicting next purchase basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:22:30.387267Z",
     "start_time": "2020-04-06T15:22:30.366085Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 2. Predicting next purchase basket\n",
    "\n",
    "\n",
    "def generate_samples_strategy_2(n_samples, users, items, hashes_container):\n",
    "    print(\"Strategy 2) Predicting next purchase basket\")\n",
    "    # Count valid users\n",
    "    valid_users = 0\n",
    "    for user in users.values():\n",
    "        if user.strategy_2_valid_partitions():\n",
    "            valid_users += 1\n",
    "\n",
    "    samples_per_user = ceil(n_samples / valid_users)\n",
    "    print(\n",
    "        f\"Valid users: {valid_users} | Samples/user: {samples_per_user}\\n\"\n",
    "        f\"Target: {n_samples} | Total samples: {valid_users * samples_per_user}\"\n",
    "    )\n",
    "    initial_collisions = hashes_container.collisions\n",
    "\n",
    "    samples = []\n",
    "    for user in tqdm(users.values(), desc=\"Valid users\"):\n",
    "        valid_partitions = user.strategy_2_valid_partitions()\n",
    "        if not valid_partitions: continue\n",
    "        # Pick visual clusters and artists liked by the user\n",
    "        liked_clusters = user.liked_clusters\n",
    "        liked_artists = user.liked_artists\n",
    "\n",
    "        n = samples_per_user\n",
    "        while n > 0:\n",
    "            ni = random.choice(items)\n",
    "            if artwork_id2cluster[ni] in liked_clusters: continue\n",
    "            if artwork_id2artist[ni] in liked_artists: continue\n",
    "            timestamp, profile, basket = random.choice(valid_partitions)\n",
    "            pi = random.choice(tuple(basket))\n",
    "            # TODO(Antonio): Not sure about this (item purchased twice)\n",
    "            if pi in profile: continue\n",
    "            triple = (profile, pi, ni, timestamp, user.user_id_hash)\n",
    "            if not hashes_container.enroll(triple): continue\n",
    "            samples.append(triple)\n",
    "            n -= 1\n",
    "    final_collisions = hashes_container.collisions\n",
    "    print(f\"Hash collisions: {final_collisions - initial_collisions}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strategy_2(samples, users, artwork_id2cluster, artwork_id2artist):\n",
    "    print(\"Strategy 2) Predicting next purchase basket\")\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni, timestamp, uid) in tqdm(samples, desc=\"Check S2\"):\n",
    "        user = users[uid]\n",
    "        gt_basket = user.baskets[timestamp]\n",
    "        previous_baskets = set(item\n",
    "                               for b_timestamp, basket in user.baskets.items()\n",
    "                               if b_timestamp < timestamp for item in basket)\n",
    "        # Positive item\n",
    "        assert pi in gt_basket\n",
    "        assert profile == previous_baskets\n",
    "        # (Might not be true)\n",
    "        assert pi not in profile\n",
    "        # Negative item\n",
    "        assert ni not in user.profile\n",
    "        assert artwork_id2cluster[ni] not in user.liked_clusters\n",
    "        assert artwork_id2artist[ni] not in user.liked_artists\n",
    "        # Profile\n",
    "        assert not gt_basket.issubset(profile)\n",
    "        assert profile.issubset(user.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:22:58.033220Z",
     "start_time": "2020-04-06T15:22:30.389181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 2) Predicting next purchase basket\n",
      "Valid users: 455 | Samples/user: 3664\n",
      "Target: 1666667 | Total samples: 1667120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81930a3100bc47c2ab6051ef636bf38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 383364\n",
      "Strategy 2) Predicting next purchase basket\n",
      "Samples: 1667120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975f9e8610b049939f633cf7094f9bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S2', max=1667120.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 2) Predicting next purchase basket\n",
      "Valid users: 455 | Samples/user: 184\n",
      "Target: 83334 | Total samples: 83720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2a45b4963b47c39dc147c449733fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 49956\n",
      "Strategy 2) Predicting next purchase basket\n",
      "Samples: 83720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075de72f338d487cbd9928415993bb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S2', max=83720.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train - Strategy 2\n",
    "samples_s2_train = generate_samples_strategy_2(\n",
    "    N_SAMPLES_PER_STRATEGY_TRAIN,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_2(\n",
    "    samples_s2_train,\n",
    "    inventory.users,\n",
    "    artwork_id2cluster,\n",
    "    artwork_id2artist,\n",
    ")\n",
    "# Validation - Strategy 2\n",
    "samples_s2_valid = generate_samples_strategy_2(\n",
    "    N_SAMPLES_PER_STRATEGY_VALID,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_2(\n",
    "    samples_s2_valid,\n",
    "    inventory.users,\n",
    "    artwork_id2cluster,\n",
    "    artwork_id2artist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Recommending visually similar artworks from favorite artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:22:58.052438Z",
     "start_time": "2020-04-06T15:22:58.036049Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 3. Recommending visually similar artworks from favorite artists\n",
    "\n",
    "\n",
    "def generate_samples_strategy_3(n_samples, users, items, hashes_container):\n",
    "    print((\"Strategy 3) Recommending visually similar \"\n",
    "           \"artworks from favorite artists\"))\n",
    "\n",
    "    # Count valid users\n",
    "    valid_users = 0\n",
    "    for user in users.values():\n",
    "        if user.strategy_3_valid_liked(artwork_cluster2id, artwork_artist2id):\n",
    "            valid_users += 1\n",
    "\n",
    "    samples_per_user = ceil(n_samples / valid_users)\n",
    "    print(\n",
    "        f\"Valid users: {valid_users} | Samples/user: {samples_per_user}\\n\"\n",
    "        f\"Target: {n_samples} | Total samples: {valid_users * samples_per_user}\"\n",
    "    )\n",
    "    initial_collisions = hashes_container.collisions\n",
    "\n",
    "    samples = []\n",
    "    for user in tqdm(users.values(), desc=\"Valid users\"):\n",
    "        valid_liked = tuple(user.strategy_3_valid_liked(artwork_cluster2id, artwork_artist2id))\n",
    "        if not valid_liked: continue\n",
    "        # Pick visual clusters and artists liked by the user\n",
    "        liked_clusters = user.liked_clusters\n",
    "        liked_artists = user.liked_artists\n",
    "\n",
    "        n = samples_per_user\n",
    "        while n > 0:\n",
    "            ni = random.choice(items)\n",
    "            if artwork_id2cluster[ni] in liked_clusters: continue\n",
    "            if artwork_id2artist[ni] in liked_artists: continue\n",
    "            pi = random.choice(valid_liked)\n",
    "            triple = (user.profile, pi, ni, user.user_id_hash)\n",
    "            if not hashes_container.enroll(triple): continue\n",
    "            samples.append(triple)\n",
    "            n -= 1\n",
    "    final_collisions = hashes_container.collisions\n",
    "    print(f\"Hash collisions: {final_collisions - initial_collisions}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strategy_3(samples, users, artwork_id2cluster, artwork_id2artist):\n",
    "    print((\"Strategy 3) Recommending visually similar \"\n",
    "           \"artworks from favorite artists\"))\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni, uid) in tqdm(samples, desc=\"Check S3\"):\n",
    "        user = users[uid]\n",
    "\n",
    "        # Positive item\n",
    "        assert pi not in user.profile\n",
    "        assert artwork_id2cluster[pi] in user.liked_clusters \n",
    "        assert artwork_id2artist[pi] in user.liked_artists \n",
    "        # Negative item\n",
    "        assert ni not in user.profile\n",
    "        assert artwork_id2cluster[ni] not in user.liked_clusters\n",
    "        assert artwork_id2artist[ni] not in user.liked_artists\n",
    "        # Profile\n",
    "        assert set(profile) == set(user.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:23:20.193967Z",
     "start_time": "2020-04-06T15:22:58.055115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 3) Recommending visually similar artworks from favorite artists\n",
      "Valid users: 2246 | Samples/user: 743\n",
      "Target: 1666667 | Total samples: 1668778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ead48c46f8e4b429c4583a9735adf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 49909\n",
      "Strategy 3) Recommending visually similar artworks from favorite artists\n",
      "Samples: 1668778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b6282ddd474a45b83352a681623844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S3', max=1668778.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 3) Recommending visually similar artworks from favorite artists\n",
      "Valid users: 2246 | Samples/user: 38\n",
      "Target: 83334 | Total samples: 85348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc2106d6b2d459e951f1dfd3b0968c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 4610\n",
      "Strategy 3) Recommending visually similar artworks from favorite artists\n",
      "Samples: 85348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f187ef0b3749aaafef6d8d0e7cd796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S3', max=85348.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train - Strategy 3\n",
    "samples_s3_train = generate_samples_strategy_3(\n",
    "    N_SAMPLES_PER_STRATEGY_TRAIN,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_3(\n",
    "    samples_s3_train,\n",
    "    inventory.users,\n",
    "    artwork_id2cluster,\n",
    "    artwork_id2artist,\n",
    ")\n",
    "# Validation - Strategy 3\n",
    "samples_s3_valid = generate_samples_strategy_3(\n",
    "    N_SAMPLES_PER_STRATEGY_VALID,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_3(\n",
    "    samples_s3_valid,\n",
    "    inventory.users,\n",
    "    artwork_id2cluster,\n",
    "    artwork_id2artist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Recommending profile items from the same user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:23:20.221068Z",
     "start_time": "2020-04-06T15:23:20.196745Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 4. Recommending profile items from the same user profile\n",
    "\n",
    "\n",
    "def generate_samples_strategy_4(n_samples, users, items, hashes_container):\n",
    "    print(\"Strategy 4) Recommending profile items from the same user profile\")\n",
    "\n",
    "    samples_per_user = ceil(n_samples / len(users))\n",
    "    print(\n",
    "        f\"Valid users: {len(users)} | Samples/user: {samples_per_user}\\n\"\n",
    "        f\"Target: {n_samples} | Total samples: {len(users) * samples_per_user}\"\n",
    "    )\n",
    "    initial_collisions = hashes_container.collisions\n",
    "\n",
    "    samples = []\n",
    "    for user in tqdm(users.values(), desc=\"Valid users\"):\n",
    "        profile = user.profile\n",
    "\n",
    "        n = samples_per_user\n",
    "        while n > 0:\n",
    "            ni = random.choice(items)\n",
    "            if ni in profile: continue\n",
    "            pi = random.choice(profile)\n",
    "            triple = (profile, pi, ni, user.user_id_hash)\n",
    "            if not hashes_container.enroll(triple): continue\n",
    "            samples.append(triple)\n",
    "            n -= 1\n",
    "    final_collisions = hashes_container.collisions\n",
    "    print(f\"Hash collisions: {final_collisions - initial_collisions}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strategy_4(samples, users):\n",
    "    print(\"Strategy 4) Recommending profile items from the same user profile\")\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni, uid) in tqdm(samples, desc=\"Check S4\"):\n",
    "        user = users[uid]\n",
    "\n",
    "        # Positive item\n",
    "        assert pi in user.profile\n",
    "        # Negative item\n",
    "        assert ni not in user.profile\n",
    "        # Profile\n",
    "        assert set(profile) == set(user.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:23:38.130278Z",
     "start_time": "2020-04-06T15:23:20.225465Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 4) Recommending profile items from the same user profile\n",
      "Valid users: 2919 | Samples/user: 571\n",
      "Target: 1666667 | Total samples: 1666749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c0e22acbfd47de88ef22178cae3df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 89803\n",
      "Strategy 4) Recommending profile items from the same user profile\n",
      "Samples: 1666749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4263117758c64944b1a8ea88ec28aceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S4', max=1666749.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 4) Recommending profile items from the same user profile\n",
      "Valid users: 2919 | Samples/user: 29\n",
      "Target: 83334 | Total samples: 84651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64637b1637c5474594283e7bd32183b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 8635\n",
      "Strategy 4) Recommending profile items from the same user profile\n",
      "Samples: 84651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812199cc848345a1bd511993e8039ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S4', max=84651.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train - Strategy 4\n",
    "samples_s4_train = generate_samples_strategy_4(\n",
    "    N_SAMPLES_PER_STRATEGY_TRAIN,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_4(\n",
    "    samples_s4_train,\n",
    "    inventory.users,\n",
    ")\n",
    "# Validation - Strategy 4\n",
    "samples_s4_valid = generate_samples_strategy_4(\n",
    "    N_SAMPLES_PER_STRATEGY_VALID,\n",
    "    inventory.users,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_4(\n",
    "    samples_s4_valid,\n",
    "    inventory.users,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Recommending profile items given an artificially created user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:23:38.147584Z",
     "start_time": "2020-04-06T15:23:38.133192Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 5. Recommending profile items from the same user profile\n",
    "\n",
    "\n",
    "def generate_samples_strategy_5(n_samples, items, hashes_container):\n",
    "    print((\"Strategy 5) Recommending profile items given \"\n",
    "           \"an artificially created user profile\"))\n",
    "\n",
    "    print(f\"Target: {n_samples} | Total samples: {n_samples}\")\n",
    "    initial_collisions = hashes_container.collisions\n",
    "\n",
    "    samples = []\n",
    "    n = n_samples\n",
    "    progress_bar = tqdm(total=n_samples, desc=\"Valid artificial profiles\")\n",
    "    while n > 0:\n",
    "        pi = random.choice(items)\n",
    "        ni = random.choice(items)\n",
    "        if ni == pi: continue\n",
    "        triple = ([pi], pi, ni)\n",
    "        if not hashes_container.enroll(triple): continue\n",
    "        progress_bar.update(1)\n",
    "        samples.append(triple)\n",
    "        n -= 1\n",
    "    progress_bar.close()\n",
    "    final_collisions = hashes_container.collisions\n",
    "    print(f\"Hash collisions: {final_collisions - initial_collisions}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strategy_5(samples):\n",
    "    print((\"Strategy 5) Recommending profile items given \"\n",
    "           \"an artificially created user profile\"))\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni) in tqdm(samples, desc=\"Check S5\"):\n",
    "        # Positive item\n",
    "        assert pi == profile[0]\n",
    "        # Negative item\n",
    "        assert ni != pi\n",
    "        # Profile\n",
    "        assert len(profile) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:24:02.835008Z",
     "start_time": "2020-04-06T15:23:38.149628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 5) Recommending profile items given an artificially created user profile\n",
      "Target: 1666667 | Total samples: 1666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4b5dd9a21d4b28bca93948ae780f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid artificial profiles', max=1666667.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 95014\n",
      "Strategy 5) Recommending profile items given an artificially created user profile\n",
      "Samples: 1666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9438d287224f4f3e866a6d7bc10d9a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S5', max=1666667.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 5) Recommending profile items given an artificially created user profile\n",
      "Target: 83334 | Total samples: 83334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbd166dfce14e45944be581e6a7bb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid artificial profiles', max=83334.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 6390\n",
      "Strategy 5) Recommending profile items given an artificially created user profile\n",
      "Samples: 83334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c6e1081a7c4d7293c1dc7bd452248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S5', max=83334.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train - Strategy 5\n",
    "samples_s5_train = generate_samples_strategy_5(\n",
    "    N_SAMPLES_PER_STRATEGY_TRAIN,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_5(\n",
    "    samples_s5_train,\n",
    ")\n",
    "# Validation - Strategy 5\n",
    "samples_s5_valid = generate_samples_strategy_5(\n",
    "    N_SAMPLES_PER_STRATEGY_VALID,\n",
    "    inventory.items,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_5(\n",
    "    samples_s5_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Artificial profile with a single item: recommend visually similar items from the same artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:24:02.870507Z",
     "start_time": "2020-04-06T15:24:02.838958Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 6. Artificial profile with a single item:\n",
    "# recommend visually similar items from the same artist\n",
    "\n",
    "\n",
    "def generate_samples_strategy_6(n_samples, items, artwork_id2artist, artwork_artist2id, hashes_container):\n",
    "    print((\"Strategy 6) Artificial profile with a single item: \"\n",
    "           \"recommend visually similar items from the same artist\"))\n",
    "\n",
    "    print(f\"Target: {n_samples} | Total samples: {n_samples}\")\n",
    "    initial_collisions = hashes_container.collisions\n",
    "\n",
    "    samples = []\n",
    "    n = n_samples\n",
    "    progress_bar = tqdm(total=n_samples, desc=\"Valid artificial profiles\")\n",
    "    while n > 0:\n",
    "        profile_item = random.choice(items)\n",
    "        profile_item_artist = artwork_id2artist[profile_item]\n",
    "        pi = random.choice(artwork_artist2id[profile_item_artist])\n",
    "        if pi == profile_item: continue\n",
    "        ni = random.choice(items)\n",
    "        if artwork_id2artist[ni] == profile_item_artist: continue\n",
    "        triple = ([profile_item], pi, ni)\n",
    "        if not hashes_container.enroll(triple): continue\n",
    "        progress_bar.update(1)\n",
    "        samples.append(triple)\n",
    "        n -= 1\n",
    "    progress_bar.close()\n",
    "    final_collisions = hashes_container.collisions\n",
    "    print(f\"Hash collisions: {final_collisions - initial_collisions}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strategy_6(samples, artwork_id2artist):\n",
    "    print((\"Strategy 6) Artificial profile with a single item: \"\n",
    "           \"recommend visually similar items from the same artist\"))\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni) in tqdm(samples, desc=\"Check S6\"):\n",
    "        # Positive item\n",
    "        assert pi != profile[0]\n",
    "        assert artwork_id2artist[profile[0]] == artwork_id2artist[pi]\n",
    "        # Negative item\n",
    "        assert ni != pi\n",
    "        assert artwork_id2artist[profile[0]] != artwork_id2artist[ni]\n",
    "        # Profile\n",
    "        assert len(profile) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:24:32.952992Z",
     "start_time": "2020-04-06T15:24:02.874448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 6) Artificial profile with a single item: recommend visually similar items from the same artist\n",
      "Target: 1666667 | Total samples: 1666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa3bd8bbc114d17b86eb7e5ebcf3408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid artificial profiles', max=1666667.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 45503\n",
      "Strategy 6) Artificial profile with a single item: recommend visually similar items from the same artist\n",
      "Samples: 1666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2686a2ca6d2041b3b45c6d8ab660deb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S6', max=1666667.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 6) Artificial profile with a single item: recommend visually similar items from the same artist\n",
      "Target: 83334 | Total samples: 83334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1a0cfcbaec4b8ea8f89265ab9c07c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid artificial profiles', max=83334.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hash collisions: 2563\n",
      "Strategy 6) Artificial profile with a single item: recommend visually similar items from the same artist\n",
      "Samples: 83334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ed4b046c404d8eb2a102443ccf1294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S6', max=83334.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training - Strategy 6\n",
    "samples_s6_train = generate_samples_strategy_6(\n",
    "    N_SAMPLES_PER_STRATEGY_TRAIN,\n",
    "    inventory.items,\n",
    "    artwork_id2artist,\n",
    "    artwork_artist2id,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_6(\n",
    "    samples_s6_train,\n",
    "    artwork_id2artist,\n",
    ")\n",
    "# Validation - Strategy 6\n",
    "samples_s6_valid = generate_samples_strategy_6(\n",
    "    N_SAMPLES_PER_STRATEGY_VALID,\n",
    "    inventory.items,\n",
    "    artwork_id2artist,\n",
    "    artwork_artist2id,\n",
    "    hashes_container,\n",
    ")\n",
    "sanity_checks_strategy_6(\n",
    "    samples_s6_valid,\n",
    "    artwork_id2artist,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:24:32.988798Z",
     "start_time": "2020-04-06T15:24:32.959201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total collisions: 888118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total collisions: {hashes_container.collisions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuples will be scored as artwork indexes in the *embedding* instead of using the hashes to improve performance in future stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:26:16.194612Z",
     "start_time": "2020-04-06T15:24:32.993830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10002856 training triples\n",
      "No duplicated hashes found\n"
     ]
    }
   ],
   "source": [
    "D_train = [\n",
    "    samples_s1_train,\n",
    "    samples_s2_train,\n",
    "    samples_s3_train,\n",
    "    samples_s4_train,\n",
    "    samples_s5_train,\n",
    "    samples_s6_train,\n",
    "]\n",
    "samples_train = [(triple[0], triple[1], triple[2])\n",
    "                 for D_i in D_train\n",
    "                 for triple in D_i]\n",
    "print(f\"There are {len(samples_train)} training triples\")\n",
    "\n",
    "# Check for duplicated triples in training samples\n",
    "hashes_container_train = HashesContainer()\n",
    "for triple in samples_train:\n",
    "    assert hashes_container_train.enroll(triple)\n",
    "print(\"No duplicated hashes found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:28:32.488723Z",
     "start_time": "2020-04-06T15:26:16.213587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Takes around 1.5 minutes\n",
    "df_train_output = pd.DataFrame(samples_train, columns=[\"profile\", \"pi\", \"ni\"])\n",
    "output_train = join(\"data\", \"UGallery\", \"train.csv\")\n",
    "df_train_output.to_csv(output_train, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:28:45.953769Z",
     "start_time": "2020-04-06T15:28:32.502283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 504137 validation triples\n",
      "No duplicated hashes found\n"
     ]
    }
   ],
   "source": [
    "D_valid = [\n",
    "    samples_s1_valid,\n",
    "    samples_s2_valid,\n",
    "    samples_s3_valid,\n",
    "    samples_s4_valid,\n",
    "    samples_s5_valid,\n",
    "    samples_s6_valid,\n",
    "]\n",
    "samples_validation = [\n",
    "    (triple[0], triple[1], triple[2])\n",
    "    for D_i in D_valid\n",
    "    for triple in D_i\n",
    "]\n",
    "print(f\"There are {len(samples_validation)} validation triples\")\n",
    "\n",
    "# Check for duplicated triples in validation samples\n",
    "hashes_container_valid = HashesContainer()\n",
    "for triple in samples_validation:\n",
    "    assert hashes_container_valid.enroll(triple)\n",
    "print(\"No duplicated hashes found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:28:50.667133Z",
     "start_time": "2020-04-06T15:28:45.958821Z"
    }
   },
   "outputs": [],
   "source": [
    "df_validation_output = pd.DataFrame(samples_validation, columns=[\"profile\", \"pi\", \"ni\"])\n",
    "output_validation = join(\"data\", \"UGallery\", \"validation.csv\")\n",
    "df_validation_output.to_csv(output_validation, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data (evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:28:50.710199Z",
     "start_time": "2020-04-06T15:28:50.669994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1073 evaluation baskets/users\n"
     ]
    }
   ],
   "source": [
    "evaluation_baskets = 0\n",
    "for uid, user in inventory.users.items():\n",
    "    evaluation_basket = user.evaluation_basket\n",
    "    if evaluation_basket == set(): continue\n",
    "    evaluation_baskets += 1\n",
    "\n",
    "print(f\"There are {evaluation_baskets} evaluation baskets/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:28:50.791662Z",
     "start_time": "2020-04-06T15:28:50.717152Z"
    }
   },
   "outputs": [],
   "source": [
    "baskets = {\n",
    "    uid: list(user.evaluation_basket)\n",
    "    for uid, user in inventory.users.items()\n",
    "}\n",
    "output_evaluation = join(\"data\", \"UGallery\", \"evaluation.json\")\n",
    "with open(output_evaluation, \"w\") as file:\n",
    "    json.dump(baskets, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_id2index = join(\"data\", \"UGallery\", \"artwork_id2index.json\")\n",
    "with open(output_id2index, \"w\") as file:\n",
    "    json.dump({k: int(v) for k, v in artwork_id2index.items()}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_id2cluster = join(\"data\", \"UGallery\", \"artwork_id2cluster.json\")\n",
    "with open(output_id2cluster, \"w\") as file:\n",
    "    json.dump({k: int(v) for k, v in artwork_id2cluster.items()}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_id2artist = join(\"data\", \"UGallery\", \"artwork_id2artist.json\")\n",
    "with open(output_id2artist, \"w\") as file:\n",
    "    json.dump({k: v for k, v in artwork_id2artist.items()}, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
