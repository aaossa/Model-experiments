{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:21.090241Z",
     "start_time": "2020-04-06T03:13:20.918212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:21.659021Z",
     "start_time": "2020-04-06T03:13:21.093864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.0.2 from /home/aaossa/.local/lib/python3.8/site-packages/pip (python 3.8)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:21.692524Z",
     "start_time": "2020-04-06T03:13:21.667361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1 (default, Jan 25 2020, 13:45:32) \n",
      "[GCC 7.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:23.280532Z",
     "start_time": "2020-04-06T03:13:21.696313Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.18.1 in /home/aaossa/.local/lib/python3.8/site-packages (from -r requirements/common.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn==0.22.2.post1 in /home/aaossa/.local/lib/python3.8/site-packages (from -r requirements/common.txt (line 2)) (0.22.2.post1)\n",
      "Requirement already satisfied: line_profiler==3.0.2 in /home/aaossa/.local/lib/python3.8/site-packages (from -r requirements/dev.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: tqdm==4.45.0 in /home/aaossa/.local/lib/python3.8/site-packages (from -r requirements/dev.txt (line 3)) (4.45.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/aaossa/.local/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1->-r requirements/common.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/aaossa/.local/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1->-r requirements/common.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: IPython in /home/aaossa/.local/lib/python3.8/site-packages (from line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (7.11.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (4.3.3)\n",
      "Requirement already satisfied: backcall in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: pygments in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (4.4.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (41.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/aaossa/.local/lib/python3.8/site-packages (from IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.15.2)\n",
      "Requirement already satisfied: ipython-genutils in /home/aaossa/.local/lib/python3.8/site-packages (from traitlets>=4.2->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: six in /home/aaossa/.local/lib/python3.8/site-packages (from traitlets>=4.2->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/aaossa/.local/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/aaossa/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.1.8)\n",
      "Requirement already satisfied: parso>=0.5.2 in /home/aaossa/.local/lib/python3.8/site-packages (from jedi>=0.10->IPython->line_profiler==3.0.2->-r requirements/dev.txt (line 2)) (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -r requirements/dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:23.498120Z",
     "start_time": "2020-04-06T03:13:23.285862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readme.txt\t\tugallery_purchases.csv\r\n",
      "ugallery_inventory.csv\tugallery_resnet50_embeddings.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/UGallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:23.652073Z",
     "start_time": "2020-04-06T03:13:23.500504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artwork_id_hash,artist_id_hash,upload_timestamp\r\n",
      "9338d925a4f391d049f1cb55be83206d,ac648ab20e0c330dcfaa912644abcc2f,0\r\n",
      "6ff620bdd4b7143ef7ef9a43ae35379f,dfc6c382d6584b22b5ba75c62cdb0c56,0\r\n",
      "ec4708be07b9b92dfd3c98b92d5b273e,e836b4d62ec611a38ce9dd6e394a65e1,1\r\n",
      "bb8fe17afcd2b8a8700155b79980a7d9,942050a4fd56327fb69ecb8b81948ded,2\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/UGallery/ugallery_inventory.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:23.823146Z",
     "start_time": "2020-04-06T03:13:23.655590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_hash,purchase_timestamp,purchased_artwork_ids_hash\r\n",
      "faaecc910173fcca8b146c66db26b99f,1416,['f196009db1ba9607150abf0570e0fffe']\r\n",
      "90d6d470c21861aaa739b2811ac0df3c,1418,['ccccb1b02d3130e435e05a4eea7d11fd']\r\n",
      "67c7793eefa4aca1cd9a18029b26efc6,1420,['7bbc45a178aef2c041f4376ecdc26b23']\r\n",
      "8c872e88b91f7077527d8c7bf8892fbd,1424,['5775ae42d3cef7ea7f56b800a8d7cffc']\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/UGallery/ugallery_purchases.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:23.998866Z",
     "start_time": "2020-04-06T03:13:23.829745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to privacy and copyright restrictions, we are only able to release part of the user transactions data, which consists of 6535 transactions of 2919 users on 6030 items.\r\n",
      "\r\n",
      "Files under this folder:\r\n",
      "\r\n",
      "* ugallery_purchases.csv  \r\n",
      "Each line is a tuple in the form of (user_id_hash, purchase_timestamp, artwork_id_hash). Note that each id_hash is an 32-char string.\r\n",
      "This file has the purchases in time for each user, the test data is the last purchase of each user.\r\n",
      "\r\n",
      "* ugallery_inventory.csv  \r\n",
      "Each line is a tuple in the form of (artwork_id_hash, artist_id_hash, upload_timestamp). Note that each id_hash is an 32-char string.\r\n",
      "This file has the time an item is added to the website inventory, because these are physical artworks, the availability of the items must be simulated in order to make the recommendations.\r\n",
      "\r\n",
      "* ugallery_resnet50_embeddings.npy\r\n",
      "This is a numpy array of shape (13297, 2), each row is of shape (2,) where the first value is the artwork_id_hash, and the second one is the Resnet50 embedding of the artwork image.\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/UGallery/Readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:24.251502Z",
     "start_time": "2020-04-06T03:13:24.004124Z"
    }
   },
   "outputs": [],
   "source": [
    "# ugallery_data_utils.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_embeddings(embedding_path, embedding_shape=(13297, 2048)):\n",
    "    data = np.load(embedding_path, allow_pickle=True)\n",
    "    # Generate indexes and contiguous embedding\n",
    "    embedding = np.empty(shape=embedding_shape)\n",
    "    artwork_id2index = dict()\n",
    "    artwork_index2id = dict()\n",
    "    for i, (artwork_id_hash, artwork_embedding) in enumerate(data):\n",
    "        artwork_id2index[artwork_id_hash] = i\n",
    "        artwork_index2id[i] = artwork_id_hash\n",
    "        embedding[i] = artwork_embedding\n",
    "    return embedding, artwork_id2index, artwork_index2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing procesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:25.181218Z",
     "start_time": "2020-04-06T03:13:24.253074Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "from os.path import join\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:25.200125Z",
     "start_time": "2020-04-06T03:13:25.183679Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating visual clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:27.433616Z",
     "start_time": "2020-04-06T03:13:25.203787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape: (13297, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings from files\n",
    "embeddings_path = join(\"data\", \"UGallery\", \"ugallery_resnet50_embeddings.npy\")\n",
    "loaded_data = load_embeddings(embeddings_path)\n",
    "embeddings, artwork_id2index, artwork_index2id = loaded_data\n",
    "print(f\"embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:28.704577Z",
     "start_time": "2020-04-06T03:13:27.436082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score normalization result shape: (13297, 2048)\n"
     ]
    }
   ],
   "source": [
    "# z-score normalization of embedding\n",
    "embeddings = StandardScaler().fit_transform(embeddings)\n",
    "print(f\"z-score normalization result shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:13:35.189115Z",
     "start_time": "2020-04-06T03:13:28.711998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduction result shape: (13297, 200)\n"
     ]
    }
   ],
   "source": [
    "# 1. Conduct PCA to reduce from R2048 to R200\n",
    "embeddings = PCA(n_components=200).fit_transform(embeddings)\n",
    "print(f\"PCA reduction result shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:09.889882Z",
     "start_time": "2020-04-06T03:13:35.191651Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score (0): 0.006115622090028127 - New highest!\n",
      ">> Best Silhouette score: 0.006115622090028127\n"
     ]
    }
   ],
   "source": [
    "# 2. Perform k-means clustering with 100 clusters 20 times\n",
    "# and keep the clusterer with the highest Silhouette coefficient\n",
    "best_score = float(\"-inf\")\n",
    "best_clusterer = None\n",
    "\n",
    "for i in range(20):\n",
    "    clusterer = KMeans(\n",
    "        n_clusters=100,\n",
    "        max_iter=2000,\n",
    "        n_init=8,\n",
    "        n_jobs=8\n",
    "    ).fit(embeddings)\n",
    "    clusterer_labels = clusterer.predict(embeddings)\n",
    "    clusterer_score = silhouette_score(embeddings, clusterer_labels)\n",
    "    if clusterer_score > best_score:\n",
    "        best_score = clusterer_score\n",
    "        best_clusterer = clusterer\n",
    "        print(f\"Silhouette score ({i}): {clusterer_score} - New highest!\")\n",
    "    else:\n",
    "        print(f\"Silhouette score ({i}): {clusterer_score}\")\n",
    "    break # TODO(Antonio): Remove this constrain\n",
    "\n",
    "print(f\">> Best Silhouette score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:10.306816Z",
     "start_time": "2020-04-06T03:14:09.914360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clusterer Silhouette score: 0.006115622090028127\n",
      "There are n_clusters: 100\n"
     ]
    }
   ],
   "source": [
    "# 3. Label each image with its respective visual cluster\n",
    "clusterer_labels = best_clusterer.predict(embeddings)\n",
    "print(f\"Best clusterer Silhouette score: {best_score}\")\n",
    "\n",
    "artwork_id2cluster = dict()\n",
    "artwork_cluster2id = defaultdict(list)\n",
    "for i, label in enumerate(clusterer_labels):\n",
    "    artwork_id = artwork_index2id[i]\n",
    "    artwork_id2cluster[artwork_id] = label\n",
    "    artwork_cluster2id[label].append(artwork_id)\n",
    "\n",
    "n_clusters = len(set(artwork_id2cluster.values()))\n",
    "print(f\"There are n_clusters: {n_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:10.396122Z",
     "start_time": "2020-04-06T03:14:10.340482Z"
    }
   },
   "outputs": [],
   "source": [
    "# ugallery_data_utils.py\n",
    "class User:\n",
    "    def __init__(self, user_id_hash):\n",
    "        self.user_id_hash = user_id_hash\n",
    "        self.baskets = dict()\n",
    "        self.gt_baskets = dict()\n",
    "        self.evaluation_basket = None\n",
    "        self.profile = None\n",
    "\n",
    "    def add_purchase(self, purchased_items, timestamp):\n",
    "        assert timestamp not in self.baskets\n",
    "        timestamp = int(timestamp)\n",
    "        # Baskets are assumed to contain each item once\n",
    "        self.baskets[timestamp] = set(purchased_items)\n",
    "        self.gt_baskets[timestamp] = set(purchased_items)\n",
    "        \n",
    "    def assert_baskets(self):\n",
    "        assert isinstance(self.baskets, dict)\n",
    "        assert isinstance(self.evaluation_basket, set)\n",
    "        assert isinstance(self.gt_baskets, dict)\n",
    "        if len(self.evaluation_basket):\n",
    "            misses = 0\n",
    "            for gt_timestamp, gt_basket in self.gt_baskets.items():\n",
    "                if gt_timestamp in self.baskets:\n",
    "                    assert gt_basket == self.baskets[gt_timestamp]\n",
    "                else:\n",
    "                    misses += 1\n",
    "                    assert gt_basket == self.evaluation_basket\n",
    "            assert misses == 1\n",
    "        else:\n",
    "            assert self.baskets == self.gt_baskets\n",
    "            \n",
    "\n",
    "    def create_profile(self):\n",
    "        assert self.profile is None\n",
    "        self.profile = list(set(\n",
    "            item\n",
    "            for basket in self.baskets.values()\n",
    "            for item in basket\n",
    "        ))\n",
    "        \n",
    "    def save_basket_for_evaluation(self):\n",
    "        assert self.evaluation_basket is None\n",
    "        # If user has a single basket, use it for training only\n",
    "        if len(self.baskets) == 1:\n",
    "            self.evaluation_basket = set()\n",
    "            return\n",
    "        # All baskets are still available in self.gt_baskets\n",
    "        last_basket_timestamp = max(self.baskets.keys())\n",
    "        assert last_basket_timestamp in self.baskets\n",
    "        last_basket = self.baskets.pop(last_basket_timestamp)\n",
    "        assert last_basket is not None\n",
    "        self.evaluation_basket = last_basket\n",
    "\n",
    "    def strategy_1_valid_baskets(self, min_size=0):\n",
    "        return [\n",
    "            (timestamp, basket)\n",
    "            for timestamp, basket in self.baskets.items()\n",
    "            if len(basket) >= min_size\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:11.623834Z",
     "start_time": "2020-04-06T03:14:10.414676Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaossa/.local/lib/python3.8/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ugallery_data_utils.py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Inventory:\n",
    "    def __init__(self, inventory_path, purchases_path):\n",
    "        # Build dataframes to manage data\n",
    "        self.inventory = pd.read_csv(inventory_path)\n",
    "        self.purchases = pd.read_csv(purchases_path)\n",
    "        self.inventory.rename(\n",
    "            columns={\"upload_timestamp\": \"timestamp\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "        self.purchases.rename(\n",
    "            columns={\"purchase_timestamp\": \"timestamp\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        # Check if artwork_id_hash has duplicates (inventory)\n",
    "        assert not self.inventory[\"artwork_id_hash\"].duplicated().any()\n",
    "        # Check for missing values in data (inventory)\n",
    "        assert not self.inventory.isnull().values.any()\n",
    "        # Check for missing values in data (purchases)\n",
    "        assert not self.purchases.isnull().values.any()\n",
    "        # Process purchased artworks column (purchases)\n",
    "        purchases_to_list = lambda p: p[1:-1].replace(\"'\", \"\").split(\", \")\n",
    "        self.purchases[\"purchased_artwork_ids_hash\"] = self.purchases[\n",
    "            \"purchased_artwork_ids_hash\"].map(purchases_to_list)\n",
    "        # Check if all purchases contain elements\n",
    "        assert all(p for p in self.purchases[\"purchased_artwork_ids_hash\"])\n",
    "\n",
    "        # Find non-unique items\n",
    "        purchased_items = self.purchases[\"purchased_artwork_ids_hash\"].sum()\n",
    "        self.non_unique_items, seen = set(), set()\n",
    "        for item in purchased_items:\n",
    "            if item not in seen:\n",
    "                seen.add(item)\n",
    "            else:\n",
    "                self.non_unique_items.add(item)\n",
    "        # Create list with items ids\n",
    "        self.items = self.inventory[\"artwork_id_hash\"].unique()\n",
    "\n",
    "        # Build\n",
    "        self.users = dict()\n",
    "        self.__build_users()\n",
    "        # Check if all users were built\n",
    "        users_in_df = set(self.purchases[\"user_id_hash\"].unique())\n",
    "        users_in_dict = set(self.users.keys())\n",
    "        assert users_in_df == users_in_dict\n",
    "        # Check if all users are present in dict\n",
    "        assert all(self.purchases[\"user_id_hash\"].isin(self.users.keys()))\n",
    "        # Check if user profiles were created\n",
    "        assert all(user.profile for user in self.users.values())\n",
    "        # Check if all users have evaluation basket or a single purchase\n",
    "        assert all(user.evaluation_basket is not None\n",
    "                   for user in self.users.values())\n",
    "        assert all(user.assert_baskets for user in self.users.values())\n",
    "\n",
    "    def available_at_t(self, up_to_timestamp=None):\n",
    "        inventory = set()\n",
    "        # Forward time by timestamp\n",
    "        for step, timestamp, row in self.__forward_time(up_to_timestamp):\n",
    "            # Add item to inventory\n",
    "            if step == \"Add item\":\n",
    "                item = row[\"artwork_id_hash\"]\n",
    "                if item in inventory:\n",
    "                    # Item already present\n",
    "                    pass\n",
    "                inventory.add(item)\n",
    "            # Remove item if purchased item is not unique\n",
    "            elif step == \"Sell items\":\n",
    "                for item in row[\"purchased_artwork_ids_hash\"]:\n",
    "                    if item not in inventory:\n",
    "                        # Item already sold or not present\n",
    "                        if item not in self.non_unique_items:\n",
    "                            # Item already sold or nor present\n",
    "                            pass\n",
    "                    if item not in self.non_unique_items:\n",
    "                        inventory.discard(item)\n",
    "        return inventory\n",
    "\n",
    "    def __build_users(self):\n",
    "        self.users = dict()\n",
    "        purchases = 0\n",
    "        inventory = 0\n",
    "        for step, timestamp, row in self.__forward_time():\n",
    "            if step != \"Sell items\":\n",
    "                inventory += 1\n",
    "                continue\n",
    "            purchases += 1\n",
    "            if row[\"user_id_hash\"] not in self.users:\n",
    "                user_id_hash = row[\"user_id_hash\"]\n",
    "                self.users[user_id_hash] = User(user_id_hash)\n",
    "            user = self.users[user_id_hash]\n",
    "            user.add_purchase(\n",
    "                row[\"purchased_artwork_ids_hash\"],\n",
    "                row[\"timestamp\"],\n",
    "            )\n",
    "        assert purchases == len(self.purchases)\n",
    "        assert inventory == len(self.inventory)\n",
    "        for _, user in self.users.items():\n",
    "            user.save_basket_for_evaluation()\n",
    "            user.create_profile()\n",
    "\n",
    "    def __forward_time(self, up_to_timestamp=None):\n",
    "        # Sort data by timestamp\n",
    "        df_inventory = self.inventory.sort_values(by=[\"timestamp\"])\n",
    "        df_purchases = self.purchases.sort_values(by=[\"timestamp\"])\n",
    "        # Limits of iteration\n",
    "        i_inventory, max_inventory = 0, len(df_inventory.index)\n",
    "        i_purchases, max_purchases = 0, len(df_purchases.index)\n",
    "        # First row of dataframes\n",
    "        row_inventory = df_inventory.loc[i_inventory, :]\n",
    "        row_purchases = df_purchases.loc[i_purchases, :]\n",
    "\n",
    "        while row_inventory is not None or row_purchases is not None:\n",
    "            # If next timestamp is an upload\n",
    "            time_inventory = getattr(row_inventory, \"timestamp\", float(\"inf\"))\n",
    "            time_purchases = getattr(row_purchases, \"timestamp\", float(\"inf\"))\n",
    "            if time_inventory <= time_purchases:\n",
    "                yield (\"Add item\", time_inventory, row_inventory)\n",
    "                i_inventory += 1\n",
    "                if i_inventory >= max_inventory:\n",
    "                    row_inventory = None\n",
    "                else:\n",
    "                    row_inventory = df_inventory.loc[i_inventory, :]\n",
    "            # If next timestamp is a purchase\n",
    "            elif time_purchases < time_inventory:\n",
    "                yield (\"Sell items\", time_purchases, row_purchases)\n",
    "                i_purchases += 1\n",
    "                if i_purchases >= max_purchases:\n",
    "                    row_purchases = None\n",
    "                else:\n",
    "                    row_purchases = df_purchases.loc[i_purchases, :]\n",
    "            # If limit was given\n",
    "            if up_to_timestamp is not None:\n",
    "                if min(time_inventory, time_purchases) > up_to_timestamp:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:11.632163Z",
     "start_time": "2020-04-06T03:14:11.626753Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_SAMPLES_TRAIN = 10_000_000\n",
    "TOTAL_SAMPLES_TEST = TOTAL_SAMPLES_TRAIN * 0.05\n",
    "\n",
    "N_STRATEGIES = 6\n",
    "N_SAMPLES_PER_STRATEGY = ceil(TOTAL_SAMPLES_TRAIN / N_STRATEGIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:15.604189Z",
     "start_time": "2020-04-06T03:14:11.637375Z"
    }
   },
   "outputs": [],
   "source": [
    "inventory_path = join(\"data\", \"UGallery\", \"ugallery_inventory.csv\")\n",
    "purchases_path = join(\"data\", \"UGallery\", \"ugallery_purchases.csv\")\n",
    "inventory = Inventory(inventory_path, purchases_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:15.616710Z",
     "start_time": "2020-04-06T03:14:15.606880Z"
    }
   },
   "outputs": [],
   "source": [
    "artwork_id2artist = dict(zip(\n",
    "        inventory.inventory[\"artwork_id_hash\"],\n",
    "        inventory.inventory[\"artist_id_hash\"],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Predicting missing item in purchase basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:15.645911Z",
     "start_time": "2020-04-06T03:14:15.620818Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Predicting missing item in purchase basket\n",
    "\n",
    "\n",
    "def generate_samples_strategy_1(n_samples, users):\n",
    "    print(\"Strategy 1) Predicting missing item in purchase basket\")\n",
    "    # Count valid users\n",
    "    valid_users = 0\n",
    "    for i, (_, user) in enumerate(users.items()):\n",
    "        if user.strategy_1_valid_baskets(min_size=2):\n",
    "            valid_users += 1\n",
    "\n",
    "    samples_per_user = ceil(n_samples / valid_users)\n",
    "    print(\n",
    "        f\"Valid users: {valid_users} | Samples/user: {samples_per_user}\\n\"\n",
    "        f\"Target: {n_samples} | Total samples: {valid_users * samples_per_user}\"\n",
    "    )\n",
    "\n",
    "    samples = []\n",
    "    for i, (uid, user) in enumerate(tqdm(users.items(), desc=\"Valid users\")):\n",
    "        # Pick items from baskets with more than one item\n",
    "        valid_baskets = user.strategy_1_valid_baskets(min_size=2)\n",
    "        if not valid_baskets: continue\n",
    "        # Pick visual clusters and artists liked by the user\n",
    "        liked_clusters = set(artwork_id2cluster[item] for item in user.profile)\n",
    "        liked_artists = set(artwork_id2artist[item] for item in user.profile)\n",
    "\n",
    "        n = samples_per_user\n",
    "        while n > 0:\n",
    "            timestamp, basket = random.choice(valid_baskets)\n",
    "            pi = random.choice(tuple(basket))\n",
    "            ni = random.choice(inventory.items)\n",
    "            if artwork_id2cluster[ni] in liked_clusters: continue\n",
    "            if artwork_id2artist[ni] in liked_artists: continue\n",
    "            n -= 1\n",
    "            profile = {item for item in basket if item != pi}\n",
    "            samples.append((profile, pi, ni, timestamp, uid))\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sanity_checks_strat_1(samples, users):\n",
    "    print(\"Strategy 1) Predicting missing item in purchase basket\")\n",
    "    print(f\"Samples: {len(samples)}\")\n",
    "    for (profile, pi, ni, timestamp, uid) in tqdm(samples, desc=\"Check S1\"):\n",
    "        user = users[uid]\n",
    "        gt_basket = user.baskets[timestamp]\n",
    "        assert len(profile) + 1 == len(gt_basket)\n",
    "        # Positive item\n",
    "        assert pi in gt_basket\n",
    "        assert pi not in profile\n",
    "        # Negative item\n",
    "        assert ni not in user.profile\n",
    "        liked_clusters = set(artwork_id2cluster[item] for item in user.profile)\n",
    "        assert artwork_id2cluster[ni] not in liked_clusters\n",
    "        liked_artists = set(artwork_id2artist[item] for item in user.profile)\n",
    "        assert artwork_id2artist[ni] not in liked_artists\n",
    "        # Profile\n",
    "        assert profile.issubset(gt_basket)\n",
    "        assert profile.issubset(user.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:33.329738Z",
     "start_time": "2020-04-06T03:14:15.655368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 1) Predicting missing item in purchase basket\n",
      "Valid users: 625 | Samples/user: 2667\n",
      "Target: 1666667 | Total samples: 1666875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc4e84f8e0948f6b552c59b84386fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Valid users', max=2919.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 1) Predicting missing item in purchase basket\n",
      "Samples: 1666875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5be3bdbbf4b4072b5c7517352be5254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Check S1', max=1666875.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "samples_s1 = generate_samples_strategy_1(\n",
    "    N_SAMPLES_PER_STRATEGY,\n",
    "    inventory.users,\n",
    ")\n",
    "sanity_checks_strat_1(\n",
    "    samples_s1,\n",
    "    inventory.users,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Predicting next purchase basket"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%lprun -f function function(args)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(f\"Debug: user {ui}/{len(users)}\", flush=True, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T03:14:33.337605Z",
     "start_time": "2020-04-06T03:14:33.333117Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Predicting next purchase basket\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
